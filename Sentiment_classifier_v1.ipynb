{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"./data/train.csv\")\n",
    "evaluation=pd.read_csv(\"./data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 tweets.\n"
     ]
    }
   ],
   "source": [
    "#twitter training data\n",
    "#the data file is available at https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "twitter_data = pd.read_csv(\"../sentiment_data_set/training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\", header=None)\n",
    "twitter_data.columns = [\"sentiment\", \"time\", \"date\", \"query\", \"username\", \"text\"]\n",
    "nb_tweets = len(twitter_data[\"text\"])\n",
    "print(f'{nb_tweets} tweets.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 train tweets.\n",
      "165777 test tweets.\n"
     ]
    }
   ],
   "source": [
    "#Choose a random sample of tweets to put in the train set and another sample for testing accuracy\n",
    "\n",
    "import random\n",
    "\n",
    "indices = random.sample(range(nb_tweets), 1600000)\n",
    "\n",
    "twitter_train_data = twitter_data.iloc[indices[:1000000]]\n",
    "nb_train_tweets = len(twitter_train_data[\"text\"])\n",
    "print(f'{nb_train_tweets} train tweets.')\n",
    "\n",
    "twitter_test_data = twitter_data.iloc[indices[1000000:]]\n",
    "nb_test_tweets = len(twitter_test_data[\"text\"])\n",
    "print(f'{nb_test_tweets} test tweets.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing functions\n",
    "\n",
    "def remove_url(text):\n",
    "    \n",
    "    while \"http\" in text :\n",
    "        start_url = 0\n",
    "        while (start_url<len(text)-3 and text[start_url:start_url+4] != \"http\") :\n",
    "            start_url += 1\n",
    "        end_url = start_url + 4\n",
    "        while (end_url<len(text) and text[end_url] != \" \") :\n",
    "            end_url += 1\n",
    "            \n",
    "        text=text[:start_url]+text[end_url+1:]\n",
    "        \n",
    "    return text\n",
    "    \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    #remove urls\n",
    "    text = remove_url(text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train set done\n",
      "preprocessing test set done\n"
     ]
    }
   ],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",preprocessor=clean_text)\n",
    "\n",
    "training_features = vectorizer.fit_transform(twitter_train_data[\"text\"])\n",
    "print(\"preprocessing train set done\")\n",
    "test_features = vectorizer.transform(twitter_test_data[\"text\"])\n",
    "print(\"preprocessing test set done\")\n",
    "\n",
    "# Training\n",
    "model = LinearSVC()\n",
    "model.fit(training_features, twitter_train_data[\"sentiment\"])\n",
    "print(\"training done\")\n",
    "y_pred = model.predict(test_features)\n",
    "print(\"predicting done\")\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(twitter_test_data[\"sentiment\"], y_pred)\n",
    "\n",
    "print(\"Accuracy on the twitter dataset: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on our covid tweets\n",
    "\n",
    "covid_train_features = vectorizer.transform(train[\"text\"])\n",
    "covid_evaluation_features = vectorizer.transform(evaluation[\"text\"])\n",
    "\n",
    "covid_train_sentiment_pred = model.predict(covid_train_features)\n",
    "covid_evaluation_sentiment_pred = model.predict(covid_evaluation_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sentiment\"] = covid_train_sentiment_pred\n",
    "evaluation[\"sentiment\"] = covid_evaluation_sentiment_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the new files\n",
    "\n",
    "np.save(\"training_v1\",train)\n",
    "np.save(\"evaluation_v1\",evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
