{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data/train.csv\")\n",
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract week day and hour from the timestamp\n",
    "\n",
    "def preprocess_day(timestamp):\n",
    "    dico_day={\"Mon\":0,\"Tue\":1,\"Wed\":2,\"Thu\":3,\"Fri\":4,\"Sat\":5,\"Sun\":6}\n",
    "    res=7*[0]\n",
    "    res[dico_day[time.ctime(int(str(timestamp)[:-3]))[:3]]]=1\n",
    "    return res\n",
    "\n",
    "def preprocess_time(timestamp):\n",
    "    res=24*[0]\n",
    "    res[int(time.ctime(int(str(timestamp)[:-3]))[11:13])]=1\n",
    "    return res\n",
    "\n",
    "df=pd.DataFrame(data[\"timestamp\"])\n",
    "data[\"day\"] = df.applymap(lambda x: preprocess_day(x))\n",
    "data[\"time\"] = df.applymap(lambda x: preprocess_time(x))\n",
    "data = data.drop(columns=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the boolean by its int value\n",
    "df=pd.DataFrame(data[\"user_verified\"])\n",
    "data[\"user_verified\"]=df.applymap(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centrer & r√©duire\n",
    "cols=[\"user_statuses_count\",\"user_followers_count\",\"user_friends_count\"]\n",
    "for c in cols:\n",
    "    df=pd.DataFrame(data[c])\n",
    "    m=data[c].mean()\n",
    "    v=math.sqrt(data[c].var())\n",
    "    data[c]=df.applymap(lambda x: (x-m)/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of \n",
    "def count_occ(s):\n",
    "    if type(s)==str:\n",
    "        return len(s.split(\",\"))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "cols=[\"user_mentions\",\"urls\"]\n",
    "for c in cols:\n",
    "    df=pd.DataFrame(data[c])\n",
    "    data[c]=df.applymap(lambda x: count_occ(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text : keep only good words ie delete stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def delete_stop(x) :\n",
    "    # coronavirus is recognised by the nlp\n",
    "    x = x.lower().replace(\"covid\",\"coronavirus\").replace(\"covid-19\",\"coronavirus\").replace(\"corona\",\"coronavirus\").replace(\"covid19\",\"coronavirus\")\n",
    "    word_tokens = word_tokenize(x)  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return filtered_sentence\n",
    "\n",
    "df=pd.DataFrame(data[\"text\"])\n",
    "data[\"clean_text\"] = df.applymap(lambda x: delete_stop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the clean words will now be transformed into (300,) vectors\n",
    "def text_to_vectors(x) :\n",
    "    res = []\n",
    "    for k in x :\n",
    "        vec = nlp(k).vector\n",
    "        if vec[0] != 0 :\n",
    "            res.append(vec)\n",
    "    return res\n",
    "\n",
    "df=pd.DataFrame(data[\"clean_text\"])\n",
    "data[\"text_vect\"] = df.applymap(lambda x: text_to_vectors(x))\n",
    "data = data.drop(columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtags\n",
    "def to_low(x):\n",
    "    try :\n",
    "        res = math.isnan(x)\n",
    "    except :\n",
    "        return x.lower()\n",
    "\n",
    "data[\"hashtags_low\"] =pd.DataFrame(data[\"hashtags\"]).applymap(lambda x: to_low(x))\n",
    "\n",
    "def construc_dic() :\n",
    "    dic = {}\n",
    "    indice = 0\n",
    "    for k in range(data.shape[0]) :\n",
    "        hashtag = data[\"hashtags_low\"][k]\n",
    "        if hashtag != None :\n",
    "            liste = hashtag.split(',')\n",
    "            for word in liste :\n",
    "                mot = word.replace(\" \",\"\")\n",
    "                if not(mot in dic) :\n",
    "                    dic[mot] = indice\n",
    "                    indice +=1\n",
    "    return dic\n",
    "\n",
    "dic = construc_dic()\n",
    "\n",
    "def hash_to_vec(x) :\n",
    "    res = []\n",
    "    if x != None :\n",
    "        x = x.lower().split(',')\n",
    "        for k in x :\n",
    "            k = k.replace(\" \",\"\")\n",
    "            res.append(dic[k])\n",
    "    return res\n",
    "\n",
    "data[\"hashtags_vec\"] =pd.DataFrame(data[\"hashtags_low\"]).applymap(lambda x: hash_to_vec(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_vect</th>\n",
       "      <th>hashtags_low</th>\n",
       "      <th>hashtags_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271991</td>\n",
       "      <td>-0.094948</td>\n",
       "      <td>-0.087929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Smh, I, give]</td>\n",
       "      <td>[[-0.38512, -0.1739, 0.25749, -0.48121, -0.136...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420002</td>\n",
       "      <td>-0.095378</td>\n",
       "      <td>-0.147277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Most, us, Human, Beings, ,, I, think, miss, b...</td>\n",
       "      <td>[[-0.19571, 0.056275, -0.096518, -0.26408, 0.3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.390231</td>\n",
       "      <td>-0.094713</td>\n",
       "      <td>-0.024234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Old, dirty, tricks, Trump, ,, ..., like, n't,...</td>\n",
       "      <td>[[0.26105, -0.043804, -0.3964, 0.022796, -0.04...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.094897</td>\n",
       "      <td>-0.095125</td>\n",
       "      <td>-0.141365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Seriously, ....., I, worked, 86, hours, last,...</td>\n",
       "      <td>[[-0.28038, 0.020129, -0.19906, -0.14018, -0.2...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.417240</td>\n",
       "      <td>-0.095381</td>\n",
       "      <td>-0.151624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[May, ALMIGHTY, ALLAH, mercy, us, ., Only, lag...</td>\n",
       "      <td>[[-0.042501, 0.090773, -0.11918, 0.12372, -0.1...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665772</th>\n",
       "      <td>665772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240463</td>\n",
       "      <td>-0.094586</td>\n",
       "      <td>-0.048750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[18, months, dawg, ?, Come, man, ...]</td>\n",
       "      <td>[[-0.10543, 0.83512, 0.60768, 0.079782, -0.002...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665773</th>\n",
       "      <td>665773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.404791</td>\n",
       "      <td>-0.094568</td>\n",
       "      <td>-0.138873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[Thank, nurses, @, StanfordEMED, family, shari...</td>\n",
       "      <td>[[-0.32633, 0.2267, -0.6039, -0.079733, -0.313...</td>\n",
       "      <td>covid19</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665774</th>\n",
       "      <td>665774</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.414123</td>\n",
       "      <td>-0.095364</td>\n",
       "      <td>-0.144089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['Post, ', pearls, Palliative, ,, End, Life, B...</td>\n",
       "      <td>[[-0.29729, 0.583285, -0.066182494, 0.15645, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665775</th>\n",
       "      <td>665775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.418550</td>\n",
       "      <td>-0.095383</td>\n",
       "      <td>-0.153710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[His, facial, expressions, kind, looking, answ...</td>\n",
       "      <td>[[0.019097, 0.23119, -0.1681, 0.1299, 0.34298,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665776</th>\n",
       "      <td>665776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.417149</td>\n",
       "      <td>-0.095323</td>\n",
       "      <td>-0.145191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[We, really, ca, n't, wait, .]</td>\n",
       "      <td>[[0.022669, 0.26819, -0.16665, -0.2336, 0.3079...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665777 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  retweet_count  user_verified  user_statuses_count  \\\n",
       "0            0              0              0             0.271991   \n",
       "1            1              0              0            -0.420002   \n",
       "2            2              0              0            -0.390231   \n",
       "3            3              0              0            -0.094897   \n",
       "4            4              0              0            -0.417240   \n",
       "...        ...            ...            ...                  ...   \n",
       "665772  665772              0              0             0.240463   \n",
       "665773  665773              1              0            -0.404791   \n",
       "665774  665774              8              0            -0.414123   \n",
       "665775  665775              0              0            -0.418550   \n",
       "665776  665776              0              0            -0.417149   \n",
       "\n",
       "        user_followers_count  user_friends_count  user_mentions  urls  \\\n",
       "0                  -0.094948           -0.087929              0     0   \n",
       "1                  -0.095378           -0.147277              0     0   \n",
       "2                  -0.094713           -0.024234              0     0   \n",
       "3                  -0.095125           -0.141365              0     0   \n",
       "4                  -0.095381           -0.151624              0     0   \n",
       "...                      ...                 ...            ...   ...   \n",
       "665772             -0.094586           -0.048750              0     0   \n",
       "665773             -0.094568           -0.138873              1     1   \n",
       "665774             -0.095364           -0.144089              0     1   \n",
       "665775             -0.095383           -0.153710              0     0   \n",
       "665776             -0.095323           -0.145191              0     0   \n",
       "\n",
       "       hashtags                    day  \\\n",
       "0           NaN  [0, 1, 0, 0, 0, 0, 0]   \n",
       "1           NaN  [0, 0, 0, 0, 0, 0, 1]   \n",
       "2           NaN  [0, 1, 0, 0, 0, 0, 0]   \n",
       "3           NaN  [0, 0, 0, 0, 0, 1, 0]   \n",
       "4           NaN  [1, 0, 0, 0, 0, 0, 0]   \n",
       "...         ...                    ...   \n",
       "665772      NaN  [0, 0, 0, 0, 0, 1, 0]   \n",
       "665773  COVID19  [0, 0, 0, 0, 1, 0, 0]   \n",
       "665774      NaN  [0, 0, 0, 0, 1, 0, 0]   \n",
       "665775      NaN  [0, 1, 0, 0, 0, 0, 0]   \n",
       "665776      NaN  [0, 0, 0, 0, 0, 1, 0]   \n",
       "\n",
       "                                                     time  \\\n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "...                                                   ...   \n",
       "665772  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "665773  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "665774  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "665775  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "665776  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                               clean_text  \\\n",
       "0                                          [Smh, I, give]   \n",
       "1       [Most, us, Human, Beings, ,, I, think, miss, b...   \n",
       "2       [Old, dirty, tricks, Trump, ,, ..., like, n't,...   \n",
       "3       [Seriously, ....., I, worked, 86, hours, last,...   \n",
       "4       [May, ALMIGHTY, ALLAH, mercy, us, ., Only, lag...   \n",
       "...                                                   ...   \n",
       "665772              [18, months, dawg, ?, Come, man, ...]   \n",
       "665773  [Thank, nurses, @, StanfordEMED, family, shari...   \n",
       "665774  ['Post, ', pearls, Palliative, ,, End, Life, B...   \n",
       "665775  [His, facial, expressions, kind, looking, answ...   \n",
       "665776                     [We, really, ca, n't, wait, .]   \n",
       "\n",
       "                                                text_vect hashtags_low  \\\n",
       "0       [[-0.38512, -0.1739, 0.25749, -0.48121, -0.136...         None   \n",
       "1       [[-0.19571, 0.056275, -0.096518, -0.26408, 0.3...         None   \n",
       "2       [[0.26105, -0.043804, -0.3964, 0.022796, -0.04...         None   \n",
       "3       [[-0.28038, 0.020129, -0.19906, -0.14018, -0.2...         None   \n",
       "4       [[-0.042501, 0.090773, -0.11918, 0.12372, -0.1...         None   \n",
       "...                                                   ...          ...   \n",
       "665772  [[-0.10543, 0.83512, 0.60768, 0.079782, -0.002...         None   \n",
       "665773  [[-0.32633, 0.2267, -0.6039, -0.079733, -0.313...      covid19   \n",
       "665774  [[-0.29729, 0.583285, -0.066182494, 0.15645, 0...         None   \n",
       "665775  [[0.019097, 0.23119, -0.1681, 0.1299, 0.34298,...         None   \n",
       "665776  [[0.022669, 0.26819, -0.16665, -0.2336, 0.3079...         None   \n",
       "\n",
       "       hashtags_vec  \n",
       "0                []  \n",
       "1                []  \n",
       "2                []  \n",
       "3                []  \n",
       "4                []  \n",
       "...             ...  \n",
       "665772           []  \n",
       "665773          [3]  \n",
       "665774           []  \n",
       "665775           []  \n",
       "665776           []  \n",
       "\n",
       "[665777 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-66a17e4479cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/train_clean.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             )\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mlibwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mpandas\\_libs\\writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data.to_csv(\"data/train_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
