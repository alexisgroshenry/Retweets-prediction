{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.71592783927917\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "data = np.load(\"data_preprocessed.npy\",allow_pickle=True)\n",
    "data=pd.DataFrame(data)\n",
    "cols = list(np.load(\"data_columns.npy\",allow_pickle=True))\n",
    "data.columns=cols\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copie=data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data in the right formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sup = copie.loc[copie[\"retweet_count\"]>1000]\n",
    "df_below_all = copie.loc[copie[\"retweet_count\"]<=1000].sample(frac = 1).reset_index(drop=True)\n",
    "df_below = df_below_all[:100000]\n",
    "data_balanced = pd.concat([df_sup,df_below])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = data_balanced.sample(frac = 1) \n",
    "data_balanced = data_balanced.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data) :\n",
    "    count = 0\n",
    "    nb = 50000\n",
    "    bad =0\n",
    "    X_all = np.zeros((data.shape[0],38))\n",
    "    y_all = np.zeros((data.shape[0],1))\n",
    "    X = np.zeros((data.shape[0],38))\n",
    "    y = np.zeros((data.shape[0],1))\n",
    "    for k in range(data.shape[0]) :\n",
    "        current = data.iloc[k]\n",
    "        if current.retweet_count == 0 and count < nb :\n",
    "            y[k,0] = current.retweet_count\n",
    "            X[k,0] = current.user_verified\n",
    "            X[k,1] = current.user_statuses_count\n",
    "            X[k,2] = current.user_followers_count\n",
    "            X[k,3] = current.user_friends_count\n",
    "            X[k,4] = current.user_mentions\n",
    "            X[k,5] = current.urls\n",
    "            X[k,6] = current.hashtags\n",
    "            X[k,7:14] = current.day\n",
    "            X[k,14:38] = current.time\n",
    "            count+=1\n",
    "        elif current.retweet_count != 0 :\n",
    "            y[k,0] = current.retweet_count\n",
    "            X[k,0] = current.user_verified\n",
    "            X[k,1] = current.user_statuses_count\n",
    "            X[k,2] = current.user_followers_count\n",
    "            X[k,3] = current.user_friends_count\n",
    "            X[k,4] = current.user_mentions\n",
    "            X[k,5] = current.urls\n",
    "            X[k,6] = current.hashtags\n",
    "            X[k,7:14] = current.day\n",
    "            X[k,14:38] = current.time\n",
    "        else : \n",
    "            bad +=1\n",
    "        \n",
    "        \n",
    "        y_all[k,0] = current.retweet_count\n",
    "        X_all[k,0] = current.user_verified\n",
    "        X_all[k,1] = current.user_statuses_count\n",
    "        X_all[k,2] = current.user_followers_count\n",
    "        X_all[k,3] = current.user_friends_count\n",
    "        X_all[k,4] = current.user_mentions\n",
    "        X_all[k,5] = current.urls\n",
    "        X_all[k,6] = current.hashtags\n",
    "        X_all[k,7:14] = current.day\n",
    "        X_all[k,14:38] = current.time\n",
    "    X = X[:data.shape[0]-bad,:]\n",
    "    y = y[:data.shape[0]-bad]\n",
    "    return X,y,X_all,y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for classification\n",
    "def create_data_classif(data) :\n",
    "    bad =0\n",
    "    X = np.zeros((data.shape[0],38))\n",
    "    y = np.zeros((data.shape[0],1))\n",
    "    for k in range(data.shape[0]) :\n",
    "        current = data.iloc[k]\n",
    "        if current.retweet_count < 1000:\n",
    "            y[k,0] = 0\n",
    "            X[k,0] = current.user_verified\n",
    "            X[k,1] = current.user_statuses_count\n",
    "            X[k,2] = current.user_followers_count\n",
    "            X[k,3] = current.user_friends_count\n",
    "            X[k,4] = current.user_mentions\n",
    "            X[k,5] = current.urls\n",
    "            X[k,6] = current.hashtags\n",
    "            X[k,7:14] = current.day\n",
    "            X[k,14:38] = current.time\n",
    "            \n",
    "        elif current.retweet_count >= 1000 :\n",
    "            y[k,0] = 1\n",
    "            X[k,0] = current.user_verified\n",
    "            X[k,1] = current.user_statuses_count\n",
    "            X[k,2] = current.user_followers_count\n",
    "            X[k,3] = current.user_friends_count\n",
    "            X[k,4] = current.user_mentions\n",
    "            X[k,5] = current.urls\n",
    "            X[k,6] = current.hashtags\n",
    "            X[k,7:14] = current.day\n",
    "            X[k,14:38] = current.time\n",
    "            \n",
    "        else : \n",
    "            bad +=1\n",
    "            \n",
    "    X = X[:data.shape[0]-bad,:]\n",
    "    y = y[:data.shape[0]-bad]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_sup, y_sup, X_all_sup, y_all_sup = create_data(df_sup)\n",
    "X_below, y_below, X_all_below, y_all_below = create_data(df_below_all)\n",
    "X_classif, y_classif = create_data_classif(data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sup = torch.from_numpy(X_sup).float()\n",
    "y_sup = torch.from_numpy(y_sup).float()\n",
    "X_all_sup = torch.from_numpy(X_all_sup).float()\n",
    "y_all_sup = torch.from_numpy(y_all_sup).float()\n",
    "\n",
    "X_below = torch.from_numpy(X_below).float()\n",
    "y_below = torch.from_numpy(y_below).float()\n",
    "X_all_below = torch.from_numpy(X_all_below).float()\n",
    "y_all_below = torch.from_numpy(y_all_below).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(X,y,size=64) :\n",
    "    res = []\n",
    "    for k in range(X.shape[0]//size) :\n",
    "        try:\n",
    "            res.append([X[k*size:(k+1)*size,:],y[k*size:(k+1)*size]])\n",
    "        except :\n",
    "            res.append([X[k*size:,:],y[k*size]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    log_interval=400\n",
    "    losss = nn.L1Loss()\n",
    "    model.train() #set model in train mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = losss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader)*data.shape[0],\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() #set model in test mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    losss = nn.L1Loss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += losss(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") #if you have a GPU with CUDA installed, this may speed up computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\anaconda3\\envs\\inf573\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, random_state=0)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "clf.fit(X_classif, y_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 99.4239840348331 %\n",
      "9632\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_classif)\n",
    "prec=len(y_classif)\n",
    "count=0\n",
    "for i in range(len(y_classif)):\n",
    "    if y_classif[i]!=pred[i]:\n",
    "        prec-=1\n",
    "    elif pred[i]==1:\n",
    "        count+=1\n",
    "print(\"precision : \"+str(prec/len(y_classif)*100)+\" %\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 98.36637748898994 %\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_all_below)\n",
    "prec=len(y_all_below)\n",
    "for i in range(len(y_all_below)):\n",
    "    if pred[i]==1.:\n",
    "        prec-=1\n",
    "print(\"precision : \"+str(prec/len(y_all_below)*100)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 94.052734375 %\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_all_sup)\n",
    "prec=len(y_all_sup)\n",
    "for i in range(len(y_all_sup)):\n",
    "    if pred[i]==0.:\n",
    "        prec-=1\n",
    "print(\"precision : \"+str(prec/len(y_all_sup)*100)+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for the low model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class low_model(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(low_model, self).__init__()\n",
    "        #insert your code here\n",
    "        self.linear1 = nn.Linear(input_size,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #initial dimensions for x will be [64, 1, 28, 28]\n",
    "        #insert your code here\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_low = low_model(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model_low.parameters(), lr=0.01) #actually SGD is just GD in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_batch(X_below[:240000,:],y_below[:240000,:],size=64)\n",
    "test_loader = create_batch(X_below[240000:,:],y_below[240000:],size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/240000 (0%)]\tLoss: 33.778866\n",
      "Train Epoch: 1 [25600/240000 (11%)]\tLoss: 11.941899\n",
      "Train Epoch: 1 [51200/240000 (21%)]\tLoss: 18.180136\n",
      "Train Epoch: 1 [76800/240000 (32%)]\tLoss: 8.201487\n",
      "Train Epoch: 1 [102400/240000 (43%)]\tLoss: 28.475744\n",
      "Train Epoch: 1 [128000/240000 (53%)]\tLoss: 4.115740\n",
      "Train Epoch: 1 [153600/240000 (64%)]\tLoss: 14.874025\n",
      "Train Epoch: 1 [179200/240000 (75%)]\tLoss: 14.555970\n",
      "Train Epoch: 1 [204800/240000 (85%)]\tLoss: 17.904186\n",
      "Train Epoch: 1 [230400/240000 (96%)]\tLoss: 14.273594\n",
      "Train Epoch: 2 [0/240000 (0%)]\tLoss: 34.351364\n",
      "Train Epoch: 2 [25600/240000 (11%)]\tLoss: 11.936251\n",
      "Train Epoch: 2 [51200/240000 (21%)]\tLoss: 18.245010\n",
      "Train Epoch: 2 [76800/240000 (32%)]\tLoss: 7.973222\n",
      "Train Epoch: 2 [102400/240000 (43%)]\tLoss: 28.484110\n",
      "Train Epoch: 2 [128000/240000 (53%)]\tLoss: 4.296146\n",
      "Train Epoch: 2 [153600/240000 (64%)]\tLoss: 14.789101\n",
      "Train Epoch: 2 [179200/240000 (75%)]\tLoss: 14.213564\n",
      "Train Epoch: 2 [204800/240000 (85%)]\tLoss: 18.047682\n",
      "Train Epoch: 2 [230400/240000 (96%)]\tLoss: 14.212005\n",
      "Train Epoch: 3 [0/240000 (0%)]\tLoss: 33.904415\n",
      "Train Epoch: 3 [25600/240000 (11%)]\tLoss: 11.902340\n",
      "Train Epoch: 3 [51200/240000 (21%)]\tLoss: 18.358315\n",
      "Train Epoch: 3 [76800/240000 (32%)]\tLoss: 8.187221\n",
      "Train Epoch: 3 [102400/240000 (43%)]\tLoss: 29.319769\n",
      "Train Epoch: 3 [128000/240000 (53%)]\tLoss: 4.489655\n",
      "Train Epoch: 3 [153600/240000 (64%)]\tLoss: 14.552988\n",
      "Train Epoch: 3 [179200/240000 (75%)]\tLoss: 14.023677\n",
      "Train Epoch: 3 [204800/240000 (85%)]\tLoss: 18.028439\n",
      "Train Epoch: 3 [230400/240000 (96%)]\tLoss: 14.079570\n",
      "Train Epoch: 4 [0/240000 (0%)]\tLoss: 33.386581\n",
      "Train Epoch: 4 [25600/240000 (11%)]\tLoss: 12.046078\n",
      "Train Epoch: 4 [51200/240000 (21%)]\tLoss: 18.428335\n",
      "Train Epoch: 4 [76800/240000 (32%)]\tLoss: 8.186151\n",
      "Train Epoch: 4 [102400/240000 (43%)]\tLoss: 29.390137\n",
      "Train Epoch: 4 [128000/240000 (53%)]\tLoss: 4.668142\n",
      "Train Epoch: 4 [153600/240000 (64%)]\tLoss: 14.476107\n",
      "Train Epoch: 4 [179200/240000 (75%)]\tLoss: 13.764287\n",
      "Train Epoch: 4 [204800/240000 (85%)]\tLoss: 17.753050\n",
      "Train Epoch: 4 [230400/240000 (96%)]\tLoss: 14.054111\n",
      "Train Epoch: 5 [0/240000 (0%)]\tLoss: 33.072853\n",
      "Train Epoch: 5 [25600/240000 (11%)]\tLoss: 12.139135\n",
      "Train Epoch: 5 [51200/240000 (21%)]\tLoss: 18.325470\n",
      "Train Epoch: 5 [76800/240000 (32%)]\tLoss: 8.375645\n",
      "Train Epoch: 5 [102400/240000 (43%)]\tLoss: 29.536816\n",
      "Train Epoch: 5 [128000/240000 (53%)]\tLoss: 4.738409\n",
      "Train Epoch: 5 [153600/240000 (64%)]\tLoss: 14.491959\n",
      "Train Epoch: 5 [179200/240000 (75%)]\tLoss: 13.482071\n",
      "Train Epoch: 5 [204800/240000 (85%)]\tLoss: 17.839609\n",
      "Train Epoch: 5 [230400/240000 (96%)]\tLoss: 14.008031\n",
      "Train Epoch: 6 [0/240000 (0%)]\tLoss: 33.287289\n",
      "Train Epoch: 6 [25600/240000 (11%)]\tLoss: 11.964133\n",
      "Train Epoch: 6 [51200/240000 (21%)]\tLoss: 18.217659\n",
      "Train Epoch: 6 [76800/240000 (32%)]\tLoss: 8.406389\n",
      "Train Epoch: 6 [102400/240000 (43%)]\tLoss: 29.710487\n",
      "Train Epoch: 6 [128000/240000 (53%)]\tLoss: 4.713543\n",
      "Train Epoch: 6 [153600/240000 (64%)]\tLoss: 14.183156\n",
      "Train Epoch: 6 [179200/240000 (75%)]\tLoss: 13.371646\n",
      "Train Epoch: 6 [204800/240000 (85%)]\tLoss: 17.255642\n",
      "Train Epoch: 6 [230400/240000 (96%)]\tLoss: 13.833444\n",
      "Train Epoch: 7 [0/240000 (0%)]\tLoss: 33.295582\n",
      "Train Epoch: 7 [25600/240000 (11%)]\tLoss: 12.035994\n",
      "Train Epoch: 7 [51200/240000 (21%)]\tLoss: 18.213169\n",
      "Train Epoch: 7 [76800/240000 (32%)]\tLoss: 8.584783\n",
      "Train Epoch: 7 [102400/240000 (43%)]\tLoss: 29.622297\n",
      "Train Epoch: 7 [128000/240000 (53%)]\tLoss: 4.589412\n",
      "Train Epoch: 7 [153600/240000 (64%)]\tLoss: 14.202868\n",
      "Train Epoch: 7 [179200/240000 (75%)]\tLoss: 13.154723\n",
      "Train Epoch: 7 [204800/240000 (85%)]\tLoss: 17.134811\n",
      "Train Epoch: 7 [230400/240000 (96%)]\tLoss: 13.887273\n",
      "Train Epoch: 8 [0/240000 (0%)]\tLoss: 33.511337\n",
      "Train Epoch: 8 [25600/240000 (11%)]\tLoss: 12.055204\n",
      "Train Epoch: 8 [51200/240000 (21%)]\tLoss: 18.277725\n",
      "Train Epoch: 8 [76800/240000 (32%)]\tLoss: 8.663601\n",
      "Train Epoch: 8 [102400/240000 (43%)]\tLoss: 29.898611\n",
      "Train Epoch: 8 [128000/240000 (53%)]\tLoss: 4.455056\n",
      "Train Epoch: 8 [153600/240000 (64%)]\tLoss: 14.067054\n",
      "Train Epoch: 8 [179200/240000 (75%)]\tLoss: 13.088650\n",
      "Train Epoch: 8 [204800/240000 (85%)]\tLoss: 17.190178\n",
      "Train Epoch: 8 [230400/240000 (96%)]\tLoss: 13.829821\n",
      "Train Epoch: 9 [0/240000 (0%)]\tLoss: 33.287064\n",
      "Train Epoch: 9 [25600/240000 (11%)]\tLoss: 12.025931\n",
      "Train Epoch: 9 [51200/240000 (21%)]\tLoss: 18.203873\n",
      "Train Epoch: 9 [76800/240000 (32%)]\tLoss: 8.642817\n",
      "Train Epoch: 9 [102400/240000 (43%)]\tLoss: 29.680593\n",
      "Train Epoch: 9 [128000/240000 (53%)]\tLoss: 4.519379\n",
      "Train Epoch: 9 [153600/240000 (64%)]\tLoss: 14.042506\n",
      "Train Epoch: 9 [179200/240000 (75%)]\tLoss: 13.056131\n",
      "Train Epoch: 9 [204800/240000 (85%)]\tLoss: 17.291052\n",
      "Train Epoch: 9 [230400/240000 (96%)]\tLoss: 13.810740\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10) :\n",
    "    train(model_low, device, train_loader, optimizer, epoch)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for the sup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sup_model(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(sup_model, self).__init__()\n",
    "        #insert your code here\n",
    "        self.linear1 = nn.Linear(input_size,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #initial dimensions for x will be [64, 1, 28, 28]\n",
    "        #insert your code here\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "         \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sup = sup_model(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model_sup.parameters(), lr=0.01) #actually SGD is just GD in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_batch(X_sup[:9000,:],y_sup[:9000,:],size=64)\n",
    "test_loader = create_batch(X_sup[9000:,:],y_sup[9000:],size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/8960 (0%)]\tLoss: 5236.511230\n",
      "Train Epoch: 2 [0/8960 (0%)]\tLoss: 3711.461182\n",
      "Train Epoch: 3 [0/8960 (0%)]\tLoss: 3668.201172\n",
      "Train Epoch: 4 [0/8960 (0%)]\tLoss: 3664.354248\n",
      "Train Epoch: 5 [0/8960 (0%)]\tLoss: 3667.925293\n",
      "Train Epoch: 6 [0/8960 (0%)]\tLoss: 3673.138672\n",
      "Train Epoch: 7 [0/8960 (0%)]\tLoss: 3681.455322\n",
      "Train Epoch: 8 [0/8960 (0%)]\tLoss: 3684.517090\n",
      "Train Epoch: 9 [0/8960 (0%)]\tLoss: 3688.407227\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10) :\n",
    "    train(model_sup, device, train_loader, optimizer, epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192  :  6102 3134\n",
      "748  :  1950 3092\n",
      "1089  :  1132 2599\n",
      "586  :  1657 3590\n",
      "25  :  3476 2942\n",
      "343  :  3553 3326\n",
      "155  :  1998 2373\n",
      "1215  :  1066 2669\n",
      "726  :  2015 2961\n",
      "863  :  5099 2743\n",
      "469  :  22877 3007\n",
      "379  :  2917 2362\n",
      "785  :  9952 2974\n",
      "1164  :  21648 2859\n",
      "559  :  1231 2806\n",
      "182  :  3336 3973\n",
      "861  :  1151 2799\n",
      "298  :  3016 3670\n",
      "588  :  2724 3719\n",
      "980  :  1156 2918\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(0,20):\n",
    "    n = random.randint(0,y_sup[9000:].shape[0])\n",
    "    print(n,\" : \",int(y_sup[9000:][n]),int(model_sup(X_sup[9000:,:][n])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = np.load(\"test_preprocessed.npy\",allow_pickle=True)\n",
    "evaluation=pd.DataFrame(evaluation)\n",
    "cols = list(np.load(\"test_columns.npy\",allow_pickle=True))\n",
    "evaluation.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>665776</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.420814</td>\n",
       "      <td>-0.0953838</td>\n",
       "      <td>-0.153247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>665777</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663227</td>\n",
       "      <td>-0.0784991</td>\n",
       "      <td>-0.14009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>665778</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.178158</td>\n",
       "      <td>-0.0952573</td>\n",
       "      <td>-0.147393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>665779</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.415311</td>\n",
       "      <td>-0.0927146</td>\n",
       "      <td>-0.154174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>665780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0921758</td>\n",
       "      <td>-0.0927412</td>\n",
       "      <td>-0.0890879</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285329</th>\n",
       "      <td>951105</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316199</td>\n",
       "      <td>2.56861</td>\n",
       "      <td>-0.152087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285330</th>\n",
       "      <td>951106</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.421606</td>\n",
       "      <td>-0.0953556</td>\n",
       "      <td>-0.153189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285331</th>\n",
       "      <td>951107</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.419271</td>\n",
       "      <td>-0.095367</td>\n",
       "      <td>-0.146813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285332</th>\n",
       "      <td>951108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0780925</td>\n",
       "      <td>0.303514</td>\n",
       "      <td>-0.139279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285333</th>\n",
       "      <td>951109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470203</td>\n",
       "      <td>0.357682</td>\n",
       "      <td>-0.136903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285334 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id user_verified user_statuses_count user_followers_count  \\\n",
       "0       665776             0           -0.420814           -0.0953838   \n",
       "1       665777             1            0.663227           -0.0784991   \n",
       "2       665778             0           -0.178158           -0.0952573   \n",
       "3       665779             1           -0.415311           -0.0927146   \n",
       "4       665780             0          -0.0921758           -0.0927412   \n",
       "...        ...           ...                 ...                  ...   \n",
       "285329  951105             1           -0.316199              2.56861   \n",
       "285330  951106             0           -0.421606           -0.0953556   \n",
       "285331  951107             0           -0.419271            -0.095367   \n",
       "285332  951108             1          -0.0780925             0.303514   \n",
       "285333  951109             1            0.470203             0.357682   \n",
       "\n",
       "       user_friends_count user_mentions urls hashtags                    day  \\\n",
       "0               -0.153247             0    0        0  [0, 1, 0, 0, 0, 0, 0]   \n",
       "1                -0.14009             0    0        0  [0, 0, 0, 0, 0, 0, 1]   \n",
       "2               -0.147393             0    0        0  [1, 0, 0, 0, 0, 0, 0]   \n",
       "3               -0.154174             0    1        0  [0, 1, 0, 0, 0, 0, 0]   \n",
       "4              -0.0890879             0    1        0  [0, 1, 0, 0, 0, 0, 0]   \n",
       "...                   ...           ...  ...      ...                    ...   \n",
       "285329          -0.152087             0    1        3  [0, 1, 0, 0, 0, 0, 0]   \n",
       "285330          -0.153189             0    1        0  [0, 0, 0, 0, 1, 0, 0]   \n",
       "285331          -0.146813             0    0        0  [1, 0, 0, 0, 0, 0, 0]   \n",
       "285332          -0.139279             0    0        0  [0, 1, 0, 0, 0, 0, 0]   \n",
       "285333          -0.136903             0    1        0  [1, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                     time  \n",
       "0       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "285329  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "285330  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "285331  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "285332  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "285333  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[285334 rows x 10 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_test(data) :\n",
    "    X_all = np.zeros((data.shape[0],38))\n",
    "    y_all = np.zeros((data.shape[0],1))\n",
    "    \n",
    "    for k in range(data.shape[0]) :\n",
    "        current = data.iloc[k]\n",
    "        y_all[k,0] = current.id\n",
    "        X_all[k,0] = current.user_verified\n",
    "        X_all[k,1] = current.user_statuses_count\n",
    "        X_all[k,2] = current.user_followers_count\n",
    "        X_all[k,3] = current.user_friends_count\n",
    "        X_all[k,4] = current.user_mentions\n",
    "        X_all[k,5] = current.urls\n",
    "        X_all[k,6] = current.hashtags\n",
    "        X_all[k,7:14] = current.day\n",
    "        X_all[k,14:38] = current.time\n",
    "\n",
    "    return X_all,y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = create_data_test(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "res=[]\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]:\n",
    "        res.append(int(model_sup(X_test[i])))\n",
    "    else:\n",
    "        res.append(int(model_low(X_test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"TweetID\"]=list(int(y) for y in y_test)\n",
    "df[\"NoRetweets\"]=res\n",
    "df.to_csv(\"res2.csv\",index=False,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58.6312])\n",
      "tensor([105.0264])\n",
      "tensor([163.6576])\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_all_below)\n",
    "err=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]:\n",
    "        err+=abs(int(model_sup(X_all_below[i]))-y_all_below[i])\n",
    "    else:\n",
    "        err+=abs((int(model_low(X_all_below[i])))-y_all_below[i])\n",
    "print(err/len(copie))\n",
    "        \n",
    "pred = clf.predict(X_all_sup)\n",
    "err2=0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]:\n",
    "        err2+=abs(int(model_sup(X_all_sup[i]))-y_all_sup[i])\n",
    "    else:\n",
    "        err2+=abs((int(model_low(X_all_sup[i])))-y_all_sup[i])\n",
    "print(err2/len(copie))\n",
    "\n",
    "print((err+err2)/len(copie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
